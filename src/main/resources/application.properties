spring.application.name=gestor360-api

spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.url=jdbc:postgresql://localhost:5432/gestor360
# spring.datasource.url=jdbc:postgresql://172.22.0.2:5432/gestor360

spring.datasource.username=postgress
spring.datasource.password=123456
spring.datasource.platform=postgresql

spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.hibernate.ddl-auto=update 
spring.jpa.show-sql=false


#Ativar o devtools:
#spring.profiles.active=dee
#spring.devtools.restart.enabled=true

#diminuir o nivel de log automatico
logging.level.org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver=OFF

##kafka local producer properties
spring.kafka.producer.bootstrap-servers=localhost:29092
spring.kafka.producer.client-id=gestor-producer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.KafkaAvroSerializer

#kafka local consumer properties
spring.kafka.consumer.bootstrap-servers=localhost:29092
spring.kafka.consumer.group-id=gestor-consumer
# a estrategia de ler a mensagem, le apartir da ultima lida
# spring.kafka.consumer.auto-offset-reset=latest
#leia todas as mensagens desde o offset mais antigo
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer

#kafka schema registry configs
spring.kafka.properties.schema.registry.url=http://0.0.0.0:8085
spring.kafka.properties.specific.avro.reader=true

#configurando nivel do log
logging.level.org.apache.kafka=WARN
logging.level.io.confluent.kafka.serializers=WARN

#topicos:
spring.kafka.consumer.topic.order= client.order.request_07
spring.kafka.consumer.topic.financial= financial_01
spring.kafka.consumer.topic.closing= closing_01



